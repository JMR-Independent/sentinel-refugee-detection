{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Train Camp Classifier\n",
    "\n",
    "Trains a ResNet-18 binary classifier (camp vs non-camp) and two baselines.\n",
    "\n",
    "**Run this notebook on Google Colab** with GPU runtime.\n",
    "\n",
    "**Input:** `data/tiles/manifest.csv`, `data/tiles/norm_stats.npz`  \n",
    "**Output:** `checkpoints/best_model.pth`, training metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Colab setup (uncomment if running on Colab) ---\n",
    "# !pip install pyyaml\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# PROJECT_DIR = '/content/drive/MyDrive/sentinel-refugee-detection'\n",
    "\n",
    "# --- Local setup ---\n",
    "PROJECT_DIR = '..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, PROJECT_DIR)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "from src.utils import load_config\n",
    "from src.data import CampTileDataset, SatelliteAugmentation\n",
    "from src.model import create_camp_classifier\n",
    "from src.train import train_model, evaluate\n",
    "\n",
    "# Device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(f'{PROJECT_DIR}/configs/default.yaml')\n",
    "tiles_dir = Path(f'{PROJECT_DIR}/data/tiles')\n",
    "\n",
    "# Load normalization stats\n",
    "stats_file = np.load(tiles_dir / 'norm_stats.npz')\n",
    "norm_stats = {'low': stats_file['low'], 'high': stats_file['high']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_config = config['augmentation']\n",
    "augmentation = SatelliteAugmentation(\n",
    "    rotation=aug_config['random_rotation'],\n",
    "    flip_h=aug_config['horizontal_flip'],\n",
    "    flip_v=aug_config['vertical_flip'],\n",
    "    brightness=aug_config['brightness_jitter'],\n",
    ")\n",
    "\n",
    "train_dataset = CampTileDataset(\n",
    "    manifest_path=tiles_dir / 'manifest.csv',\n",
    "    split='train',\n",
    "    transform=augmentation,\n",
    "    normalize=True,\n",
    "    norm_stats=norm_stats,\n",
    ")\n",
    "\n",
    "val_dataset = CampTileDataset(\n",
    "    manifest_path=tiles_dir / 'manifest.csv',\n",
    "    split='val',\n",
    "    transform=None,  # No augmentation for validation\n",
    "    normalize=True,\n",
    "    norm_stats=norm_stats,\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_dataset)} tiles\")\n",
    "print(f\"Val: {len(val_dataset)} tiles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train ResNet-18 Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_camp_classifier(config)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "history = train_model(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    config=config,\n",
    "    device=device,\n",
    "    checkpoint_dir=f'{PROJECT_DIR}/checkpoints',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history['train_loss'], label='Train')\n",
    "axes[0].plot(history['val_loss'], label='Val')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Loss')\n",
    "axes[0].legend()\n",
    "\n",
    "# Precision & Recall\n",
    "axes[1].plot(history['val_precision'], label='Precision')\n",
    "axes[1].plot(history['val_recall'], label='Recall')\n",
    "axes[1].plot(history['val_f1'], label='F1')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_title('Precision / Recall / F1')\n",
    "axes[1].legend()\n",
    "\n",
    "# AUC\n",
    "axes[2].plot(history['val_auc'])\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('AUC')\n",
    "axes[2].set_title('ROC-AUC')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{PROJECT_DIR}/training_curves.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Best val metrics:\")\n",
    "best_epoch = np.argmin(history['val_loss'])\n",
    "print(f\"  Epoch: {best_epoch + 1}\")\n",
    "print(f\"  Precision: {history['val_precision'][best_epoch]:.3f}\")\n",
    "print(f\"  Recall: {history['val_recall'][best_epoch]:.3f}\")\n",
    "print(f\"  F1: {history['val_f1'][best_epoch]:.3f}\")\n",
    "print(f\"  AUC: {history['val_auc'][best_epoch]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from src.model import extract_band_features, ndvi_threshold_classifier\n",
    "\n",
    "# Extract features from train and val sets\n",
    "train_tiles = [np.load(row['path']) for _, row in\n",
    "               train_dataset.manifest.iterrows()]\n",
    "train_labels = [CampTileDataset.LABEL_MAP.get(row['label'], 0)\n",
    "                for _, row in train_dataset.manifest.iterrows()]\n",
    "\n",
    "val_tiles = [np.load(row['path']) for _, row in\n",
    "             val_dataset.manifest.iterrows()]\n",
    "val_labels = [CampTileDataset.LABEL_MAP.get(row['label'], 0)\n",
    "              for _, row in val_dataset.manifest.iterrows()]\n",
    "\n",
    "X_train, y_train = extract_band_features(train_tiles, train_labels)\n",
    "X_val, y_val = extract_band_features(val_tiles, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest baseline\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "rf.fit(X_train, y_train)\n",
    "rf_preds = rf.predict(X_val)\n",
    "rf_probs = rf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "print(\"=== Random Forest Baseline ===\")\n",
    "print(classification_report(y_val, rf_preds, target_names=['non-camp', 'camp']))\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_val, rf_probs):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NDVI threshold baseline\n",
    "ndvi_preds, ndvi_scores = ndvi_threshold_classifier(val_tiles, threshold=-0.1)\n",
    "\n",
    "print(\"=== NDVI Threshold Baseline ===\")\n",
    "print(classification_report(y_val, ndvi_preds, target_names=['non-camp', 'camp']))\n",
    "if len(np.unique(y_val)) > 1:\n",
    "    print(f\"ROC-AUC: {roc_auc_score(y_val, -ndvi_scores):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparison Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL COMPARISON (Validation Set)\")\n",
    "print(\"=\"*50)\n",
    "print(f\"{'Model':<20} {'Precision':>10} {'Recall':>10} {'F1':>10} {'AUC':>10}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'ResNet-18':<20} {history['val_precision'][best_epoch]:>10.3f} \"\n",
    "      f\"{history['val_recall'][best_epoch]:>10.3f} \"\n",
    "      f\"{history['val_f1'][best_epoch]:>10.3f} \"\n",
    "      f\"{history['val_auc'][best_epoch]:>10.3f}\")\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "print(f\"{'Random Forest':<20} {precision_score(y_val, rf_preds):>10.3f} \"\n",
    "      f\"{recall_score(y_val, rf_preds):>10.3f} \"\n",
    "      f\"{f1_score(y_val, rf_preds):>10.3f} \"\n",
    "      f\"{roc_auc_score(y_val, rf_probs):>10.3f}\")\n",
    "\n",
    "print(f\"{'NDVI Threshold':<20} {precision_score(y_val, ndvi_preds):>10.3f} \"\n",
    "      f\"{recall_score(y_val, ndvi_preds):>10.3f} \"\n",
    "      f\"{f1_score(y_val, ndvi_preds):>10.3f} \"\n",
    "      f\"{'N/A':>10}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
