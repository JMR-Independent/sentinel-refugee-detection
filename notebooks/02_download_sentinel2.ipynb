{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Download Sentinel-2 Imagery\n",
    "\n",
    "Downloads Sentinel-2 L2A tiles and computes derived indices.\n",
    "\n",
    "**Key design decisions:**\n",
    "- Download at **128x128 px** (1.28 km) for more context, resize to 64 for the CNN\n",
    "- Save **derived indices** (RGB + NDVI + NDBI + SWIR_ratio) not raw bands\n",
    "- Track **scene_id** per tile for leakage-free splitting\n",
    "\n",
    "**Run this notebook on Google Colab** for faster downloads.\n",
    "\n",
    "**Input:** `data/labels/all_locations.csv`  \n",
    "**Output:** `data/sentinel2/{tile_id}.npy` (6-channel: RGB + indices, 128x128 px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Colab setup (uncomment if running on Colab) ---\n",
    "# !pip install pystac-client planetary-computer rasterio pyproj pyyaml\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# PROJECT_DIR = '/content/drive/MyDrive/sentinel-refugee-detection'\n",
    "\n",
    "# --- Local setup ---\n",
    "PROJECT_DIR = '..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, PROJECT_DIR)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from pathlib import Path\n",
    "from src.utils import load_config, search_sentinel2, download_tile, save_tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(f'{PROJECT_DIR}/configs/default.yaml')\n",
    "locations = pd.read_csv(f'{PROJECT_DIR}/data/labels/all_locations.csv')\n",
    "output_dir = Path(f'{PROJECT_DIR}/data/sentinel2')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Locations to download: {len(locations)}\")\n",
    "print(locations['label'].value_counts())\n",
    "print(f\"\\nTile size: {config['tile_size_download']}px = {config['tile_size_download'] * config['resolution']}m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download all tiles\n",
    "\n",
    "For each location:\n",
    "1. Search for least cloudy Sentinel-2 scene\n",
    "2. Download 6 raw bands\n",
    "3. Compute derived indices: RGB + NDVI + NDBI + SWIR_ratio\n",
    "4. Save the **index tile** (what the model sees)\n",
    "5. Track the **scene_id** for leakage-free splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = config['bands']\n",
    "tile_size = config['tile_size_download']  # 128\n",
    "resolution = config['resolution']\n",
    "\n",
    "success = 0\n",
    "failures = []\n",
    "scene_ids = {}  # tile_id -> scene_id mapping\n",
    "\n",
    "for i, row in locations.iterrows():\n",
    "    tile_id = row['tile_id']\n",
    "    out_path = output_dir / f\"{tile_id}.npy\"\n",
    "    \n",
    "    # Skip if already downloaded\n",
    "    if out_path.exists():\n",
    "        # Try to load scene_id from metadata\n",
    "        meta_path = out_path.with_suffix('.json')\n",
    "        if meta_path.exists():\n",
    "            import json\n",
    "            with open(meta_path) as f:\n",
    "                scene_ids[tile_id] = json.load(f).get('scene_id', 'unknown')\n",
    "        success += 1\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        items = search_sentinel2(row['lat'], row['lon'], config, max_items=3)\n",
    "        \n",
    "        if not items:\n",
    "            failures.append((tile_id, 'no scenes found'))\n",
    "            continue\n",
    "        \n",
    "        # download_tile now returns (raw_tile, index_tile, meta)\n",
    "        raw_tile, index_tile, meta = download_tile(\n",
    "            items[0], row['lat'], row['lon'],\n",
    "            bands=bands, tile_size=tile_size, resolution=resolution,\n",
    "        )\n",
    "        \n",
    "        # Validate\n",
    "        if index_tile.shape != (6, tile_size, tile_size):\n",
    "            failures.append((tile_id, f'wrong shape {index_tile.shape}'))\n",
    "            continue\n",
    "        \n",
    "        if np.isnan(index_tile).any():\n",
    "            failures.append((tile_id, 'contains NaN'))\n",
    "            continue\n",
    "        \n",
    "        # Save the INDEX tile (RGB + NDVI + NDBI + SWIR_ratio)\n",
    "        save_tile(index_tile, out_path, meta)\n",
    "        scene_ids[tile_id] = meta.get('scene_id', 'unknown')\n",
    "        success += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        failures.append((tile_id, str(e)))\n",
    "    \n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"Progress: {i+1}/{len(locations)} \"\n",
    "              f\"(success={success}, failures={len(failures)})\")\n",
    "    \n",
    "    time.sleep(0.5)\n",
    "\n",
    "print(f\"\\nDone! Success: {success}, Failures: {len(failures)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save scene_id mapping for leakage-free splitting\n",
    "locations['scene_id'] = locations['tile_id'].map(scene_ids).fillna('unknown')\n",
    "locations.to_csv(f'{PROJECT_DIR}/data/labels/all_locations.csv', index=False)\n",
    "\n",
    "n_scenes = locations['scene_id'].nunique()\n",
    "print(f\"Unique Sentinel-2 scenes: {n_scenes}\")\n",
    "print(f\"Scene IDs will be used for leakage-free train/val split\")\n",
    "\n",
    "if failures:\n",
    "    print(f\"\\nFailed downloads ({len(failures)}):\")\n",
    "    for tile_id, reason in failures[:10]:\n",
    "        print(f\"  {tile_id}: {reason}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check: visualize tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "camp_files = sorted(output_dir.glob('camp_*.npy'))[:4]\n",
    "neg_files = sorted(output_dir.glob('neg_*.npy'))[:4]\n",
    "\n",
    "for files, ax_row, title in [(camp_files, axes[0], 'Camps'), \n",
    "                              (neg_files, axes[1], 'Negatives')]:\n",
    "    for f, ax in zip(files, ax_row):\n",
    "        tile = np.load(f)  # (6, 128, 128): R, G, B, NDVI, NDBI, SWIR_ratio\n",
    "        rgb = tile[:3].transpose(1, 2, 0)  # Already R, G, B\n",
    "        rgb = np.clip(rgb / np.percentile(rgb, 98), 0, 1)\n",
    "        ax.imshow(rgb)\n",
    "        ax.set_title(f.stem, fontsize=8)\n",
    "        ax.axis('off')\n",
    "    ax_row[0].set_ylabel(title, fontsize=14)\n",
    "\n",
    "plt.suptitle('Sample Tiles (RGB from derived channels, 128x128)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Also show the derived indices for one tile\n",
    "if camp_files:\n",
    "    tile = np.load(camp_files[0])\n",
    "    channel_names = ['Red', 'Green', 'Blue', 'NDVI', 'NDBI', 'SWIR_ratio']\n",
    "    fig, axes = plt.subplots(1, 6, figsize=(18, 3))\n",
    "    for ch, ax, name in zip(range(6), axes, channel_names):\n",
    "        im = ax.imshow(tile[ch], cmap='RdYlGn' if 'NDV' in name else 'viridis')\n",
    "        ax.set_title(name)\n",
    "        ax.axis('off')\n",
    "        plt.colorbar(im, ax=ax, fraction=0.046)\n",
    "    plt.suptitle(f'All 6 Channels: {camp_files[0].stem}', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
